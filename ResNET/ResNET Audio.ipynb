{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import  torch\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchaudio import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import ToTensor\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import librosa\n",
    "from torchaudio.datasets import SPEECHCOMMANDS\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shwet\\anaconda3\\Lib\\site-packages\\torch\\cuda\\memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "c:\\Users\\shwet\\anaconda3\\Lib\\site-packages\\torch\\cuda\\memory.py:356: FutureWarning: torch.cuda.reset_max_memory_cached now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.reset_max_memory_cached()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.batch_norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.batch_norm2(out)\n",
    "        if self.i_downsample:\n",
    "            residual = self.i_downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet_audio(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=35): \n",
    "        super(ResNet_audio, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1 = nn.Conv1d(self.in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.blocks = nn.Sequential(*[Block(64, 64) for _ in range(18)])\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(64, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.blocks(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsetSC(SPEECHCOMMANDS):\n",
    "    def __init__(self, subset: str = None):\n",
    "        super().__init__(\"./\", download=True)\n",
    "\n",
    "        def load_list(filename):\n",
    "            filepath = os.path.join(self._path, filename)\n",
    "            with open(filepath) as fileobj:\n",
    "                return [os.path.normpath(os.path.join(self._path, line.strip())) for line in fileobj]\n",
    "\n",
    "        if subset == \"validation\":\n",
    "            self._walker = load_list(\"validation_list.txt\")\n",
    "        elif subset == \"testing\":\n",
    "            self._walker = load_list(\"testing_list.txt\")\n",
    "        elif subset == \"training\":\n",
    "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
    "            excludes = set(excludes)\n",
    "            self._walker = [w for w in self._walker if w not in excludes]\n",
    "\n",
    "\n",
    "# Create training and testing split of the data\n",
    "train_set = SubsetSC(\"training\")\n",
    "test_set = SubsetSC(\"testing\")\n",
    "\n",
    "waveform, sample_rate, label, speaker_id, utterance_number = train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"labels.txt\", \"r\") as f:\n",
    "  labels = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing on audio files\n",
    "new_sr = 8000\n",
    "transform = torchaudio.transforms.Resample(orig_freq = sample_rate, new_freq= new_sr)\n",
    "tranformed = transform(waveform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding each word using its index in the list of labels.\n",
    "def label_to_index(word):\n",
    "    # Return the position of the word in labels\n",
    "    return torch.tensor(labels.index(word))\n",
    "\n",
    "\n",
    "def index_to_label(index):\n",
    "    # Return the word corresponding to the index in labels\n",
    "    # This is the inverse of label_to_index\n",
    "    return labels[index]\n",
    "\n",
    "def pad_sequence(batch):\n",
    "    batch = [item.t() for item in batch]\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
    "    return batch.permute(0, 2, 1)\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    tensors , targets = [], []\n",
    "    for waveform, _, label, _, *_ in batch:\n",
    "        tensors+=[waveform]\n",
    "        targets += [label_to_index(label)]\n",
    "        \n",
    "    tensors = pad_sequence(tensors)\n",
    "    targets = torch.stack(targets)\n",
    "    return tensors, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "#Creatting data loaders \n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collate_fn,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=custom_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2:   0%|          | 0/1326 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 449827\n"
     ]
    }
   ],
   "source": [
    "model =  ResNet_audio().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "log_interval = 20\n",
    "n_epoch = 2\n",
    "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "pbar = tqdm(total=len(train_loader), desc=f\"Train Epoch: {n_epoch}\")\n",
    "losses = []\n",
    "n = count_parameters(model)\n",
    "print(\"Number of parameters: %s\" % n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        data = transform(data)\n",
    "        output = model(data)\n",
    "\n",
    "        # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n",
    "        loss = F.nll_loss(output.squeeze(), target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print training stats\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "        # record loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "def number_of_correct(pred, target):\n",
    "    # count number of correct predictions\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "\n",
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        data = transform(data)\n",
    "        output = model(data)\n",
    "\n",
    "        pred = get_likely_index(output)\n",
    "        correct += number_of_correct(pred, target)\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.update(pbar_update)\n",
    "\n",
    "    print(f\"\\nTest Epoch: {epoch}\\tAccuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2:   0%|          | 0/1326 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/84843 (0%)]\tLoss: -0.017201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/84843 (2%)]\tLoss: -120.796265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [2560/84843 (3%)]\tLoss: -363.083557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3840/84843 (5%)]\tLoss: -755.386597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [5120/84843 (6%)]\tLoss: -1391.872681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6400/84843 (8%)]\tLoss: -2297.681641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [7680/84843 (9%)]\tLoss: -3356.276855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [8960/84843 (11%)]\tLoss: -4758.924805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [10240/84843 (12%)]\tLoss: -6321.746094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [11520/84843 (14%)]\tLoss: -7988.089355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [12800/84843 (15%)]\tLoss: -10205.018555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [14080/84843 (17%)]\tLoss: -12424.139648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [15360/84843 (18%)]\tLoss: -15084.214844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [16640/84843 (20%)]\tLoss: -17732.595703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [17920/84843 (21%)]\tLoss: -20927.837891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [19200/84843 (23%)]\tLoss: -24216.140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [20480/84843 (24%)]\tLoss: -27779.611328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [21760/84843 (26%)]\tLoss: -31469.582031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [23040/84843 (27%)]\tLoss: -34274.175781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [24320/84843 (29%)]\tLoss: -39634.574219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [25600/84843 (30%)]\tLoss: -43450.867188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [26880/84843 (32%)]\tLoss: -47728.886719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [28160/84843 (33%)]\tLoss: -53648.863281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [29440/84843 (35%)]\tLoss: -57341.113281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [30720/84843 (36%)]\tLoss: -62965.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [32000/84843 (38%)]\tLoss: -69576.398438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [33280/84843 (39%)]\tLoss: -74544.507812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [34560/84843 (41%)]\tLoss: -81950.187500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [35840/84843 (42%)]\tLoss: -87096.039062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [37120/84843 (44%)]\tLoss: -95217.187500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [38400/84843 (45%)]\tLoss: -99870.812500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [39680/84843 (47%)]\tLoss: -107233.492188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [40960/84843 (48%)]\tLoss: -113601.539062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [42240/84843 (50%)]\tLoss: -122581.078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [43520/84843 (51%)]\tLoss: -130041.406250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [44800/84843 (53%)]\tLoss: -135287.078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [46080/84843 (54%)]\tLoss: -146403.062500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [47360/84843 (56%)]\tLoss: -152853.531250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [48640/84843 (57%)]\tLoss: -159492.906250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [49920/84843 (59%)]\tLoss: -168776.937500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [51200/84843 (60%)]\tLoss: -177649.218750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [52480/84843 (62%)]\tLoss: -187902.718750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [53760/84843 (63%)]\tLoss: -196294.281250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [55040/84843 (65%)]\tLoss: -201768.343750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [56320/84843 (66%)]\tLoss: -213462.750000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [57600/84843 (68%)]\tLoss: -221516.234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [58880/84843 (69%)]\tLoss: -229966.937500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 0.6228304405874554/2 [23:54<52:52, 2303.71s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mn_epoch) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m         train(model, epoch, log_interval)\n\u001b[0;32m      5\u001b[0m         test(model, epoch)\n",
      "Cell \u001b[1;32mIn[60], line 26\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, epoch, log_interval)\u001b[0m\n\u001b[0;32m     24\u001b[0m pbar\u001b[38;5;241m.\u001b[39mupdate(pbar_update)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# record loss\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transform.to(device)\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        train(model, epoch, log_interval)\n",
    "        test(model, epoch)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
